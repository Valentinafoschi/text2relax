{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMEAtopehOeteX+yJHB9PAP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valentinafoschi/text2relax/blob/main/rumori_bianchi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "questo progetto ha come obiettivo quello di generare un audio + video rilassanti a partire da una descrizione testuale.\n",
        "\n",
        "testo --> paesaggi sonori + visivi"
      ],
      "metadata": {
        "id": "FX3LxX-J9Dtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3qgrPufe816-"
      },
      "outputs": [],
      "source": [
        "# INSTALLAZIONE LIBRERIE NECESSARIE\n",
        "\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install open-clip-torch==2.24.0 moviepy==1.0.3 librosa==0.10.2.post1 soundfile==0.12.1 scipy==1.11.4 numpy==1.26.4 scikit-learn==1.4.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "di seguito importiamo tutte le librerie necessarie per il progetto\n"
      ],
      "metadata": {
        "id": "LwSKDtcmGT8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, random, math, colorsys, re\n",
        "from typing import Dict, Any, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import librosa, soundfile as sf\n",
        "from scipy.signal import butter, lfilter, fftconvolve\n",
        "from moviepy.editor import AudioFileClip, VideoClip\n",
        "\n",
        "import open_clip\n",
        "\n",
        "# CREAZIONE CARTELLE BASE PROGETTO\n",
        "for d in [\"data\",\"results\",\"checkpoints\"]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "# seed + device\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2bvLI1CLFWVV",
        "outputId": "a415164e-bde5-4fee-ce2b-95ce8b212a76"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "scegliamo le caratteristiche visive che il nostro modello deve generare e i tipi di audio che dovrà poi prevedere.\n",
        "pattern scelti:\n",
        "- **electric** --> lampi o scariche che attraversano lo schermo\n",
        "***snow** ---> fiocchi di neve che cadono\n",
        "***waves** --> onde sinusoidali lente\n",
        "***ripple** --> onde circolari concentriche tipo goccia in acqua\n",
        "***rotating shapes** --> cerchi, quadrati o triangoli che ruotano lentamente\n",
        "\n"
      ],
      "metadata": {
        "id": "CXzs5cweGZSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_TYPES = [\"white\", \"pink\", \"brown\", \"blue\"]\n",
        "PATTERNS = [\"electric\", \"snow\", \"waves\", \"ripple\", \"rotatingShapes\"]\n",
        "\n",
        "RANGES = {\n",
        "    # AUDIO\n",
        "    \"duration_sec\": (30, 90),\n",
        "    \"lp_cutoff\": (300, 8000),   # filtro low-pass\n",
        "    \"hp_cutoff\": (20, 2000),    # filtro high-pass\n",
        "    \"reverb_mix\": (0.0, 0.6),   # quantità di riverbero\n",
        "    \"fade_in_sec\": (0.0, 5.0),  # durata del fade-in\n",
        "    \"fade_out_sec\": (0.0, 5.0), # durata del fade-out\n",
        "    \"rain_level\": (0.0, 1.0),   # intensità del pioggia\n",
        "    \"waves_level\": (0.0, 1.0),  # intensità delle onde\n",
        "    \"ripple_level\": (0.0, 1.0), # intensità delle goccie\n",
        "\n",
        "    # VIDEO\n",
        "    \"hue_main\": (0.0, 1.0),     # tonalità colore HSV\n",
        "    \"sat\": (0.2, 1.0),          # saturazione colore HSV\n",
        "    \"value\": (0.2, 1.0),        # luminosità colore HSV\n",
        "    \"motion_speed\": (0.05, 0.6),    # velocità movimento\n",
        "    \"motion_amplitude\": (0.1, 1.0), # ampiezza movimento\n",
        "    \"scene_brightness\": (0.2, 1.0), # luminosità globale\n",
        "    \"sync_to_audio\": (0.0, 1.0),    # sincronizzazione con audio\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# funzione per normalizzare un parametro\n",
        "def norm_param (name, x):\n",
        "  lo, hi = RANGES[name]\n",
        "  return (x - lo) / (hi - lo + 1e-9)\n",
        "\n",
        "\n",
        "# funzione per denormalizzare un parametro\n",
        "def denorm_param (name, x01):\n",
        "  lo, hi = RANGES[name]\n",
        "  return float(lo + x01 * (hi - lo))"
      ],
      "metadata": {
        "id": "qk7OTXpoJAjQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nella cella seguente ci occupiamo del renderer audio, cioè la parte che a partire dai parametri audio previsti dal modello genera il file .wav vero e proprio."
      ],
      "metadata": {
        "id": "sHPJx6-VOGgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SR = 22050 # quante vote viene campionato il segnale audio\n",
        "\n",
        "# filtraggio frequenza\n",
        "def _butter_filter (x, cutoff, btype):\n",
        "  if cutoff <= 0:\n",
        "    return x\n",
        "  nyq = 0.5 * SR\n",
        "  cutoff = min(cutoff, nyq-100)\n",
        "  b, a = butter(4, cutoff / nyq, btype=btype)\n",
        "  return lfilter(b, a, x)\n",
        "\n",
        "# generazione rumore base\n",
        "def _gen_noise (kind, n):\n",
        "  if kind == \"white\": #frequenze uguali\n",
        "    x = np.random.randn(n)\n",
        "  elif kind==\"pink\": # più energia sulle basse frequenze\n",
        "    x = _butter_filter(np.random.randn(n), 500, 'low')\n",
        "  elif kind==\"brown\": # ancora più basse frequenze\n",
        "    x = np.cumsum(np.random.randn(n)); x /= (np.abs(x).max()+1e-9)\n",
        "  elif kind==\"blue\": # frequenze più alte\n",
        "    x = _butter_filter(np.random.randn(n), 3000, 'high')\n",
        "  return x.astype(np.float32)\n",
        "\n",
        "# genera un'onda alla frequenza\n",
        "def _sine(freq, n): t = np.arange(n)/SR; return np.sin(2*np.pi*freq*t).astype(np.float32)\n",
        "\n",
        "#simula le gocce di pioggia\n",
        "def _rain(n, level):\n",
        "    if level<=1e-3: return np.zeros(n, np.float32)\n",
        "    y = np.zeros(n, np.float32); drops = int(level*3*n/SR)\n",
        "    for _ in range(drops):\n",
        "        i = np.random.randint(0, n-200)\n",
        "        y[i:i+200] += (np.hanning(200)*np.random.uniform(0.3,1.0)).astype(np.float32)\n",
        "    return _butter_filter(y, 8000, 'low')\n",
        "\n",
        "# genera le onde del mare\n",
        "def _waves(n, level):\n",
        "    if level<=1e-3: return np.zeros(n, np.float32)\n",
        "    base = _sine(np.random.uniform(0.1,0.25), n)*0.3\n",
        "    mod  = _sine(np.random.uniform(0.01,0.05), n)*0.7 + 0.7\n",
        "    return (base*mod*level).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "# FUNZIONE PRINCIPALE DI RENDERING AUDIO\n",
        "\n",
        "def render_audio(params: Dict[str, Any], out_wav: str):\n",
        "    n = int(params[\"duration_sec\"]*SR)\n",
        "    x = _gen_noise(params[\"noise_type\"], n)\n",
        "    if params[\"lp_cutoff\"]>0: x = _butter_filter(x, params[\"lp_cutoff\"], 'low')\n",
        "    if params[\"hp_cutoff\"]>0: x = _butter_filter(x, params[\"hp_cutoff\"], 'high')\n",
        "    x = 0.7*x + 0.2*_rain(n, params[\"rain_level\"]) + 0.3*_waves(n, params[\"waves_level\"])\n",
        "    if params[\"reverb_mix\"]>0:\n",
        "        ir = np.exp(-np.linspace(0,1.0,int(0.12*SR))).astype(np.float32)\n",
        "        wet = fftconvolve(x, ir)[:n]\n",
        "        x = (1-params[\"reverb_mix\"])*x + params[\"reverb_mix\"]*wet\n",
        "    fi = int(params[\"fade_in_sec\"]*SR); fo = int(params[\"fade_out_sec\"]*SR)\n",
        "    if fi>0: x[:fi] *= np.linspace(0,1,fi)\n",
        "    if fo>0: x[-fo:] *= np.linspace(1,0,fo)\n",
        "    x /= (np.abs(x).max()+1e-9)\n",
        "    sf.write(out_wav, x, SR); return out_wav"
      ],
      "metadata": {
        "id": "4IQwq-MENtey"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mw-hTn-zTRWQ"
      }
    }
  ]
}